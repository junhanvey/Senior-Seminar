---
title: "Foul Play? How Officiating and Penalties Influence Game Outcomes in the National Football League"
author: "Jun Hanvey"
date: "ECON4950, Spring 2024"
output: pdf_document
header-includes:
   - \usepackage{multirow}
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
urlcolor: blue
fig_width: 5
fig_height: 3
---

# Introduction


It's January 20th, 2019. Drew Brees attempts a pass to Tommylee Lewis. There's 1:49 to go in the fourth quarter of the NFC Championship. Lewis is hit, hard, by Nickell Robey-Coleman. Robey-Coleman never turns his head to look at the ball. Three officials discuss. There is no foul on the play. The New Orleans Saints settle for a field goal. They eventually lose the game, sending the Los Angeles Rams to the Super Bowl. Drew Brees, one of the most decorated and admired quarterbacks to ever play the game goes on to retire the next season, unable to lead his team to another Super Bowl. Robey-Coleman's actions in the 2018 NFC Championship, to many, appear to be an unquestionable case of defensive pass interference. Rule 8.5.2(a) of the NFL Rulebook states that "contact by a player who is not playing the ball that restricts the opponent's opportunity to make the catch" is prohibited (Goodell 32).
But what was the true effect of this highly controversial no-call? 

A 2019 article published by The Ringer calls it "the worst missed call in NFL playoff history." In fact, the title of the article is "Ball Does Lie: The Saints Just Lost on the Worst Missed Call in NFL Playoff History." (Heifetz) But did the New Orleans Saints truly lose due to the missed call? What inflammatory headlines and angry tweets don't mention is that the Saints kicked a field goal after the missed call, the Rams responded with one of their own, and the game went into overtime before their eventual victory. The missed call may have been egregious, but how can it definitively be said that the Saints would've gone to the Super Bowl had the defensive pass interference been called? 

I intend to explore the true influence of fouls on whether a team loses or wins any given football game. A foul in the National Football League (NFL) is "any infraction of a playing rule for which a penalty is prescribed (Goodell 5)." "Penalty" is the term attributed to the punishment for a foul. In this paper, I will use the term "penalty" to refer to fouls, as I am analyzing the influence of fouls which were called and led to a team being penalized. 

A simple Google search for "nfl officiating outrage" returns 79,000 results in 0.4 seconds detailing how a team or player is outraged over a call from a certain game. The outrage is understandable, given that officiating is largely subjective. While there are clearly defined rules for what is and is not allowed in a game, officials (or referees) are only human. In real time, it can be very difficult to correctly adjudicate every play or action taken by a player. This has led to a belief that referees "take sides" or that games are "rigged." After the infamous 2019 NFC championship no-call, New Orleans Saints defensive end Cameron Jordan stated  “As far as I’ve known, we haven’t had referees that go gung-ho for the Saints. We’ve got to put ourselves in the best position so we’re not able to be touched (Cacciola)." My goal is to analyze the available data and support the theory that individual officiating decisions do not determine the outcomes of NFL games. 

# Literature Review

# Data

These data come from Pro Football Reference and nflpenalties.com(include citations).
The dataset obtained from Pro Football Reference contains information about a team's performance in a given game.
The dataset from nflpenalties.com contains information about the penalties received in a given game.
After merging the two together, I then generated some variables I believed may be relevant to my analysis.
The data include information on the 2022-2023 NFL regular seasons.
I chose those seasons in order to hopefully mitigate variations caused by institutional changes due to the COVID-19 pandemic.

It should be noted that each game technically has two observations.
I did this because my model predicts a teams' odds of winning a given game.
(a binary variable) and so there had to be wins and losses in the data.
So, a hypothetical game between the Dallas Cowboys and the New York Jets would have two entries: one from the Cowboys' "perspective" which lists how many penalties they received, how many points they scored, etc. and one from the Jets' "perspective" containing the same information.
Here is a sample of the data:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(vtable)
library(caret)
library(psych)
library(car)
knitr::opts_chunk$set(fig.width=5, fig.height=3) 
```

```{r, include = F}
df <- read_csv('nfl.csv') 

```

```{r, echo = F, eval = T}
head(df)

```
# Exploratory Data Analysis
![](sumstats.png)

```{r, echo = F}
dfNum <- df[,7:18]
#             
# names <- c("Mean", "Standard Deviation", "Minimum", "25%", 
#            "Median", "75%", "Maximum")
# 
# vars <- c("Points", "Offensive Yards", "Penalty Yards", "Penalties",
#           "Turnovers", "Turnover Diff.", "Penalty Diff.",
#           "Point Diff.", "Offensive Yards Diff.",
#           "Penalty Yard Diff.")
# 
# stats <- c('mean(x)', 'sd(x)', "min(x)", 'pctile(x)[25]',
#            "median(x)", "pctile(x)[75]", "max(x)")
# 
# widths <- c(25, 5, 25, 10, 7.5, 10, 7.5, 10)
# 
# sumStats <- sumtable(dfNum, summ.names = names, labels = vars, add.median = T,
#                      col.width = widths, summ = stats)
```

```{r, echo = F, eval = T}
# totalHome <- sum(df$home)
# homeWins <- sum(df$home*df$won)
# homeLosses <- totalHome - homeWins
# awayWins <- homeLosses
# awayLosses <- homeWins

```



```{r, include = F}
refStats <- read_csv('refStats.csv')
```

```{r, Total Penalties by Crew, echo = F, eval = T}
ggplot(refStats, aes(x = crew, y = penalties)) +
  geom_bar(stat = "identity", fill = "blue4", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Referee Crew", y = "Total Penalties")
```

It should be noted that both Alan Eck and Jerome Boger only officiated games for one of the two seasons in my data.
To account for the disparity in games between different crews, I also have plotted average penalties per game by crew.

```{r, Penalties/Game by Crew, echo = F, eval = T}
ggplot(refStats, aes(x = crew, y = penalties/games)) +
  geom_bar(stat = "identity", fill = "blue4", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Referee Crew", y = "Penalties per Game")
```

Each bar represents the difference between penalties called on the away team and penalties called on the home team over the two seasons by crew.
It should be noted that many of the referees officiated roughly 30 games over the course of the two seasons.

```{r, home penalties-away, echo = F, eval = T}
x <- refStats$aPen - refStats$hPen

ggplot(refStats, aes(x = crew, y = x)) +
  geom_bar(stat = "identity", fill = "blue4", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Referee Crew", y = "Difference in Away - Home")
```

This next graph represents total penalties over the two seasons for all 32 teams.
It is arranged in ascending order.
The following graph charts how many wins each team had.
It is arranged in the same order.
As you can see, there is a lot of fluctuation, giving some insight into the effect of penalties on winning.

```{r, penalties by team, echo = F}
teamPen <- df |> 
  group_by(team) |> 
  summarise(penalties = sum(pCount), 
            wins = sum(won)) |> 
  arrange(desc(penalties))

ggplot(teamPen, aes(x = reorder(team, penalties), y = penalties)) +
  geom_bar(stat = "identity", fill = "blue4", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Team", y = "Penalties from 22-23 Seasons") 
```

```{r, number of wins per team, echo = F, eval = T}
ggplot(teamPen, aes(x = reorder(team, penalties), y = wins)) +
  geom_bar(stat = "identity", fill = "blue4", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Team", y = "Wins in 22-23 Seasons") 
```

```{r, wins correlated with penalties, echo = F, eval = T}
ggplot(teamPen, aes(x = penalties, y = wins)) +
  geom_point() +
  ggtitle("Correlation Between Number of Wins and Penalties") +
  theme_minimal() +
  labs(x = "Total Penalties", y = "Wins (out of a possible 34)") 
```

```{r, echo = F}
# pairs.panels(dfNum[1:6], cor = TRUE)
```

```{r, echo = F}
# pairs.panels(dfNum[6:12], cor = TRUE)
```


```{r, echo = F}
df$won <- as.factor(df$won)
df$home <- as.factor(df$home)
df <- df |> 
  mutate(
    
   hWin = case_when((home == "1" & won == "1") ~ 1, 
                    .default = 0)
  )
set.seed(1)
testIndex <- createDataPartition(df$won, times = 1, p = 0.7,
                                 list = F)
train <- df[testIndex, ]
test <- df[-testIndex, ]
```

# Models
To run these models, I split my data into a training set and a testing set with 70% of the original data and 30% of the original data, respectively. Until I determine my final model, all models and analysis will be based on the training set only. 
```{r}
penMod <- glm(won ~ pCount + pYards + penDiff + pYdDiff, data = train, 
              family = "binomial")
summary(penMod)

```
```{r}
y = predict(penMod, train, type = "response")

y_hat0 <- ifelse(y > .50, 1, 0) |>
  factor(levels = levels(train$won))

lgCm0 <- confusionMatrix(data = y_hat0, reference = train$won, positive = "1")
lgCm0
```
This first regression model estimates $won = \beta_0 + \beta_1(penalty count) + \beta_2(penalty yards) + \beta_3(penalty differential) + \beta_4(penalty yard differential)$. This model only predicts wins and losses with 52.04% accuracy, and none of the coefficients are significant at any level. So, not off to a great start. (insert model summaries)
```{r, echo = F, eval = T}
mod1 <- glm(won ~ oYards + points + to + tDiff + penDiff + ydsDiff +
            pYdDiff + home, data = train, family = "binomial")
summary(mod1)
```
```{r, echo = F, eval = T}
vif1 <- vif(mod1)
vif1
```
All VIFs for this model are <5, which is great. We can assume that multicollinearity is not going to be an issue here. Furthermore, it seems safe to assume that the coefficients are relatively trustworthy. 
(insert model summaries)
```{r, echo = F, eval = T}
y = predict(mod1, train, type = "response")

y_hat <- ifelse(y > .50, 1, 0) |>
  factor(levels = levels(train$won))

lgCm <- confusionMatrix(data = y_hat, reference = train$won, positive = "1")
lgCm
```

(insert confusion matrices)
The model predicts wins and losses with 87.92% accuracy, which is pretty good. I used a cutoff of 0.5 probability of winning to determine if a team should be classified as winning or losing. The only penalty-related coefficient significant at any level ($p = 0.0348$) is penalty yard differential. A 1-yard increase in penalty yard differential leads to a predicted change in win probability by a factor of $e^{-0.0137}$, or 0.9864. This equates to a roughly 1.5% reduction in winning odds. It is important to remember that the standard deviation of that variable is 31, meaning a one standard deviation increase in penalty yard differential would lead to a factor change of 0.654, or a reduction by a factor of roughly 0.346. (follow up on this because it feels wrong.)(odds ratio)
```{r, echo = F, eval = T}
mod2 <- glm(hWin ~ points + to + tDiff + penDiff + ydsDiff +
            pYdDiff + home + crew, data = train, family = "binomial")
summary(mod2)
```
#add separate models for penalty differential and penalty yard differential?
```{r, echo = F, eval = T}
vif2 <- vif(mod2)
vif2
```
```{r, echo = F, eval = T}
y = predict(mod2, train, type = "response")

y_hat <- ifelse(y > .50, 1, 0) |>
  factor(levels = levels(train$won))

lgCm <- confusionMatrix(data = y_hat, reference = train$won, positive = "1")
lgCm
```


To assess potential reference bias, I created variable named "hWin" which equals 1 if the winning team was also the home team. This model assesses how a teams odds of winning when they are the home team change based on referee crew. It will include all the same variables as the previous model, with 18 dummy variables (one for each crew.)


# Conclusion 
# Works Cited

Goodell, Roger. "OFFICIAL PLAYING RULES OF THE NATIONAL FOOTBALL LEAGUE." 
  2023. 2.14.1(a)
  
Cacciola, Scott. “Missed Call Dooms Saints, Thrills Rams and Pains New 
  Orleans.” The New York Times, The New York Times, 21 Jan. 2019,
  www.nytimes.com/2019/01/20/sports/saints-rams-call-officials.html. 
 
Heifetz, Danny. “Ball Does Lie: The Saints Just Lost on the Worst Missed Call   in NFL Playoff History.” The Ringer, The Ringer, 21 Jan. 2019, 
  www.theringer.com/nfl/2019/1/20/18190982/saints-rams-nfc-championship-game
  -missed-pass-interference-nickell-robey-coleman-tommylee-lewis. 
  
Sports Reference LLC. "2022 NFL Weekly League Schedule." 
  Pro-Football-Reference.com - Pro Football Statistics and History. 
  28 Mar. 2024, https://www.pro-football-reference.com/. 
  
Sports Reference LLC. "2023 NFL Weekly League Schedule." 
  Pro-Football-Reference.com - Pro Football Statistics and History. 
  28 Mar. 2024, https://www.pro-football-reference.com/. 
 


